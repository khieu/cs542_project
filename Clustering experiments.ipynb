{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 103 548\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "data,meta = arff.loadarff(\"PhishingData.arff\")\n",
    "meta\n",
    "data_ = data.astype(np.dtype([('SFH', 'int64'), ('popUpWidnow', 'int64'), ('SSLfinal_State', 'int64'), ('Request_URL', 'int64'), ('URL_of_Anchor', 'int64'), ('web_traffic', 'int64'), ('URL_Length', 'int64'), ('age_of_domain', 'int64'), ('having_IP_Address', 'int64'), ('Result', 'int64')]))\n",
    "\n",
    "count_1 = 0; count_neg_1 = 0; count_0 = 0\n",
    "\n",
    "\n",
    "partition_by_classes = {\n",
    "    -1: [],\n",
    "    0:[],\n",
    "    1: []\n",
    "}\n",
    "neg_class = [np.array(point.item()) for point in data_ if point[-1] == -1]\n",
    "zero_class = [np.array(point.item()) for point in data_ if point[-1] == 0]\n",
    "one_class = [np.array(point.item()) for point in data_ if point[-1] == 1]\n",
    "# for point in data_:\n",
    "#     if point[-1] == 1:\n",
    "#        count_1 += 1\n",
    "#     elif point[-1] == -1:\n",
    "#         count_neg_1 +=1\n",
    "#     else:\n",
    "#         count_0 +=1\n",
    "# print(count_neg_1, count_0, count_1)\n",
    "print(len(neg_class), len(zero_class), len(one_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "# Implementing K fold cross validation\n",
    "\n",
    "def create_k_fold(data, k):\n",
    "    k_subset = []\n",
    "    start_point = 0\n",
    "    for i in range(k):\n",
    "        if i == k -1:\n",
    "            k_subset.append(data[start_point:])\n",
    "            continue\n",
    "        rough_size = len(data) //k;\n",
    "        subset = data[start_point:start_point + rough_size]\n",
    "        k_subset.append(subset)\n",
    "        start_point = start_point + rough_size\n",
    "    \n",
    "    return k_subset\n",
    "\n",
    "k_neg_class = create_k_fold(neg_class, 10)\n",
    "k_zero_class = create_k_fold(zero_class, 10)\n",
    "k_one_class = create_k_fold(one_class, 10)\n",
    "\n",
    "# getting train and test data from k partitioned data set\n",
    "\n",
    "def get_train_test_data(i):\n",
    "    test = k_neg_class[i] + k_one_class[i] + k_zero_class[i]\n",
    "    train = []\n",
    "    for j in range(len(k_neg_class)):\n",
    "        if j != i:\n",
    "            train = train + k_neg_class[j]\n",
    "    for j in range(len(k_one_class)):\n",
    "        if j != i:\n",
    "            train = train + k_one_class[j]\n",
    "    for j in range(len(k_zero_class)):\n",
    "        if j != i:\n",
    "            train = train + k_zero_class[j]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def count_class(c):\n",
    "    class_1 = 0; class_0 = 0; class_neg = 0\n",
    "    for i in c:\n",
    "        if i[-1] == 0:\n",
    "            class_0 +=1\n",
    "        elif i[-1] == 1:\n",
    "            class_1 +=1\n",
    "        else:\n",
    "            class_neg +=1\n",
    "    return class_neg, class_0, class_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def KClustering(train):\n",
    "    k=3\n",
    "    p_1 = train[0]\n",
    "    p_2 = train[len(train)-1]\n",
    "    p_3 = train[len(train)//2]\n",
    "    p_1 = p_1[:-1]\n",
    "    p_2 = p_2[:-1]\n",
    "    p_3 = p_3[:-1]\n",
    "    for i in range(50):\n",
    "        c_1 = []; c_2 = []; c_3 = []\n",
    "        for point in train:\n",
    "            p = point\n",
    "            d_1 = np.linalg.norm(p[:-1] - p_1)\n",
    "            d_2 = np.linalg.norm(p[:-1] - p_2)\n",
    "            d_3 = np.linalg.norm(p[:-1] - p_3)\n",
    "            d_min = min(d_1,d_2,d_3)\n",
    "            if d_min == d_1:\n",
    "                c_1.append(p)\n",
    "            elif d_min == d_2:\n",
    "                c_2.append(p)\n",
    "            else:\n",
    "                c_3.append(p)\n",
    "        c_1_no_label = [x[:-1] for x in c_1]\n",
    "        c_2_no_label = [x[:-1] for x in c_2]\n",
    "        c_3_no_label = [x[:-1] for x in c_3]\n",
    "        p_1 = np.mean(c_1_no_label, axis = 0)\n",
    "        p_2 = np.mean(c_2_no_label, axis = 0)\n",
    "        p_3 = np.mean(c_3_no_label, axis = 0)\n",
    "        if i % 10 == 0:\n",
    "            print(\"$$$$$$$$$$$$$$$$$$$$$$ %s $$$$$$$$$$$$\" % i)\n",
    "            class_neg, class_0, class_1 = count_class(c_1)\n",
    "            print(\"cluster #1: -1:%s 0:%s 1:%s\" % (class_neg, class_0, class_1))\n",
    "            class_neg, class_0, class_1 = count_class(c_2)\n",
    "            print(\"cluster #2: -1:%s 0:%s 1:%s\" % (class_neg, class_0, class_1))\n",
    "            class_neg, class_0, class_1 = count_class(c_3)\n",
    "            print(\"cluster #3: -1:%s 0:%s 1:%s\" % (class_neg, class_0, class_1))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$ 0 $$$$$$$$$$$$\n",
      "cluster #1: -1:333 0:16 1:200\n",
      "cluster #2: -1:46 0:56 1:239\n",
      "cluster #3: -1:251 0:18 1:47\n",
      "$$$$$$$$$$$$$$$$$$$$$$ 10 $$$$$$$$$$$$\n",
      "cluster #1: -1:173 0:19 1:118\n",
      "cluster #2: -1:31 0:31 1:279\n",
      "cluster #3: -1:426 0:40 1:89\n",
      "$$$$$$$$$$$$$$$$$$$$$$ 20 $$$$$$$$$$$$\n",
      "cluster #1: -1:173 0:19 1:118\n",
      "cluster #2: -1:31 0:31 1:279\n",
      "cluster #3: -1:426 0:40 1:89\n",
      "$$$$$$$$$$$$$$$$$$$$$$ 30 $$$$$$$$$$$$\n",
      "cluster #1: -1:173 0:19 1:118\n",
      "cluster #2: -1:31 0:31 1:279\n",
      "cluster #3: -1:426 0:40 1:89\n",
      "$$$$$$$$$$$$$$$$$$$$$$ 40 $$$$$$$$$$$$\n",
      "cluster #1: -1:173 0:19 1:118\n",
      "cluster #2: -1:31 0:31 1:279\n",
      "cluster #3: -1:426 0:40 1:89\n",
      "cluster #1: -1:630 0:90 1:486\n"
     ]
    }
   ],
   "source": [
    "train, test = get_train_test_data(9)\n",
    "KClustering(train)\n",
    "class_neg, class_0, class_1 = count_class(train)\n",
    "print(\"cluster #1: -1:%s 0:%s 1:%s\" % (class_neg, class_0, class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=3, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# TRAINING GAUSSIAN MIXTURE MODEL\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=3)\n",
    "# train = [np.array(point.item()) for point in train]\n",
    "train_no_label = [p[:-1] for p in train]\n",
    "\n",
    "gmm.fit(train_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 630\n",
      "all instances from Class 1 is labeled as\n",
      "cluster1: 188   cluster2: 186   cluster3: 256 \n",
      "\n",
      "all instances from Class 2 is labeled as\n",
      "cluster1: 34   cluster2: 50   cluster3: 6 \n",
      "\n",
      "all instances from Class 3 is labeled as\n",
      "cluster1: 178   cluster2: 235   cluster3: 73 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FITTING THE DATA AND PRINTOUT HOW MANY OF EACH CLASS IS CORRECTLY/INCORRECTLY MISCLUSTERED\n",
    "\n",
    "c_1 = 0; c_2 = 0; c_3 = 0\n",
    "c = 0\n",
    "\n",
    "for i in range(630):\n",
    "    p = train[i]\n",
    "    if p[-1] == 0:\n",
    "        c_1 +=1\n",
    "    elif p[-1] == 1:\n",
    "        c_2 +=1\n",
    "    else:\n",
    "        c_3 +=1\n",
    "print(c_1,c_2,c_3)\n",
    "    \n",
    "labels = gmm.predict(train_no_label[:630])\n",
    "# print(labels)\n",
    "count_diff = 0\n",
    "c_1 = 0; c_2 = 0; c_3 = 0\n",
    "for i in range(630):\n",
    "    label = labels[i]\n",
    "    if label == 0:\n",
    "        c_1 +=1\n",
    "    elif label == 1:\n",
    "        c_2 +=1\n",
    "    else:\n",
    "        c_3 +=1\n",
    "print(\"all instances from Class 1 is labeled as\")\n",
    "print(\"cluster1: %s   cluster2: %s   cluster3: %s \\n\" %(c_1,c_2,c_3))\n",
    "labels = gmm.predict(train_no_label[630:630+90])\n",
    "# print(labels)\n",
    "count_diff = 0\n",
    "c_1 = 0; c_2 = 0; c_3 = 0\n",
    "for i in range(90):\n",
    "    label = labels[i]\n",
    "    if label == 0:\n",
    "        c_1 +=1\n",
    "    elif label == 1:\n",
    "        c_2 +=1\n",
    "    else:\n",
    "        c_3 +=1\n",
    "print(\"all instances from Class 2 is labeled as\")\n",
    "print(\"cluster1: %s   cluster2: %s   cluster3: %s \\n\" %(c_1,c_2,c_3))\n",
    "labels = gmm.predict(train_no_label[720:])\n",
    "# print(labels)\n",
    "count_diff = 0\n",
    "c_1 = 0; c_2 = 0; c_3 = 0\n",
    "for i in range(486):\n",
    "    label = labels[i]\n",
    "    if label == 0:\n",
    "        c_1 +=1\n",
    "    elif label == 1:\n",
    "        c_2 +=1\n",
    "    else:\n",
    "        c_3 +=1\n",
    "print(\"all instances from Class 3 is labeled as\")\n",
    "print(\"cluster1: %s   cluster2: %s   cluster3: %s \\n\" %(c_1,c_2,c_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
